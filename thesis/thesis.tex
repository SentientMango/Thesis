\documentclass[11pt,a4paper,openright,twoside]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{caption}
\usepackage{float}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{afterpage}

\setlength{\parindent}{0.2em}
\setlength{\parskip}{0.5em}
%\setlength{\textfloatsep}{10pt plus 1.0pt minus 2.0pt}

\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=12mm,
}

\newcommand{\ZZ}{$ZZ\to ll\nu\nu$ }
\newcommand{\Zg}{$Z\gamma\to ll\gamma$ }
\newcommand{\llM}{$ll+E_T^{miss}$ }
\newcommand{\met}{$E_T^{miss}$ }
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}    

\begin{document}
\begin{titlepage}
\centering
\includegraphics[width=0.9\linewidth]{Title_Head.png}
\vfill
{\Huge Estimating \ZZ background in the \llM final state using \Zg data\\\vspace{1cm}\Large A Thesis \\}
\vspace{1cm}
{\Large submitted to\\Indian Institue of Science Education and Research, Pune\\ in partial fulfillment of the requirements for the \\BS-MS Dual Degree Programme\vspace{1cm}\\by\vspace{1cm}\\Mangesh Sonawane\vspace{0.2cm}\\Registration Number: 20121083\\}
\vspace{1cm}
\includegraphics[scale=0.8]{iiser_logo.png}
\vfill
{\Large Indian Institute of Science Education and Research, Pune\vspace{0.1cm}\\Dr. Homi Bhabha Road,\vspace{0.3cm}\\ Pashan, Pune 411008, INDIA}
\vfill
\vfill
\end{titlepage}
\pagestyle{empty}
\begin{center}
{\large June 2017 - April 2018\\}
\vspace{10cm}
\large 
Conducted at : DESY\\
Notkestra\ss e 85,\\
22607, Hamburg\\
Germany\\
\vspace{10cm}
Supervisor: Dr. Beate Heinemann\\
\copyright Mangesh Sonawane 2018\\
All rights reserved
\vfill
\newpage
\Huge \textbf{Certificate\\}
\end{center}
\vspace{1cm}
\normalsize This is to certify that this dissertation, entitled "Estimating \ZZ background in the \llM final status using \Zg data", submitted towards the partial fulfilment of the BS-MS dual degree programme at the Indian Institute of Science Education and Research (IISER), Pune, represents the work carried out by Mangesh Sonawane at the Deutsches Elektronen-Synchrotron (DESY), Hamburg, under the supervision of Dr. Beate Heinemann, Professor of Experimental Particle Physics at the Institute of Physics, University of Freiburg, during the academic year 2017-2018.
\vfill
\begin{center}
Mangesh Sonawane\hspace{8cm}
Dr. Beate Heinemann
\end{center}
\vfill
Committee:\\
Dr. Beate Heinemann\\
Dr. Seema Sharma
\vfill
\vfill
\newpage
\blankpage
\newpage
\topskip0pt
\vspace*{\fill}
\noindent I dedicate this thesis to my parents, Avinash and Ranjana Sonawane, my mentors, Dr. Sourabh Dube and Dr. Seema Sharma, and to my friends and colleagues and IISER, without whose timely advice and support this thesis would not have been made possible.
\vspace*{\fill}
\newpage
\blankpage
\newpage
\begin{center}
\Huge \textbf{Declaration\\}
\end{center}
\vspace{1cm}
\normalsize I hereby declare that the matter containined within the thesis entitled "Estimating \ZZ background in the \llM final status using \Zg data", contains the results of the work carried out by me at the Deutsches Elektronen-Synchrotron (DESY) Hamburg, under the supervision of Dr. Beate Heinemann, and the same has not been submitted elsewhere for any other degree.
\vfill
\begin{center}
Mangesh Sonawane\hspace{8cm}
Dr. Beate Heinemann
\end{center}
\vfill
Committee:\\
Dr. Beate Heinemann\\
Dr. Seema Sharma
\vfill
\vfill
\newpage
\blankpage
\newpage
{\Huge \textbf{Acknowledgements\vspace{2cm}\\}}
I would like to express my deepest gratitude for Dr. Beate Heinemann for her guidance and patient mentoring. It's not just technical skills that I have acquired under her supervision, but also an understanding of how a physicist approaches the subject and tackles the inevitable problems that surface.\vspace{1cm}

$\langle$ placeholder $\rangle$

\newpage
\blankpage
\newpage

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\pagenumbering{roman}
\setcounter{page}{1}
In the search for Dark Matter (DM) at the LHC, SM particles are produced in association with DM particles, which are invisible as they don't interact with the detector. Thus events with large imbalance in transverse momentum are of interest. One such signature is $ll + E_T^{miss}$. The dominant background contributing to the search for DM in the $ll + E_T^{miss}$ is $ZZ \rightarrow ll\nu\nu$.  Currently, this background is determined using Monte Carlo simulation, with an uncertainty of $\approx 10\%$ \cite{ZH_ATLAS}. The goal of this study is to establish a data driven method to estimate this background, and reduce the uncertainty. Using \Zg, which is a process with low backgrounds and has a high $BR*\sigma$, it is possible to estimate the \ZZ contribution. In regions where $p_{T}(\gamma) \gg M_{Z}$, the two processes are kinematically similar. They have the same production mechanisms, but differ due to the photon and Z boson couplings to the quarks being different, as well as the difference in mass (photons are massless, while Z bosons are massive). Introducing a transfer factor $R$ as the ratio $\sigma(ZZ)/\sigma(Z\gamma)$ which is determined from simulation, the contribution of \ZZ to the background can be estimated from \Zg data. The uncertainty on the prediction of $R$ due to theoretical aspects is estimated in this work.
\thispagestyle{plain}
\tableofcontents
\thispagestyle{empty}
\cleardoublepage
\pagenumbering{arabic}
\chapter{Introduction}
\pagestyle{plain}
\setcounter{page}{1}
Fundamental particle physics has a remarkable goal. It attempts to explain the interactions of matter and energy with the minimum possible number mathematical presumptions, with everything else in the universe being an emergent property.

Not only is it remarkably ambitious, the Standard Model of physics is one of the most successful theories developed, describing the fundamental particles and their interactions\cite{griff}. It is theoretically self-consistent, and has enjoyed tremendous success in providing accurate experimental predictions. However, the Standard Model is not complete theory of fundamental interactions. It does not provide an explanation for several observed phenomena, such as gravity, or the accelerating expansion of the universe, among others.

One such question that triggers burning curiosity is the apparent incongruity of galaxy rotation curves with the theory of Newtonian mechanics: stars in the arms of spiral galaxies appear to move much faster than Newtonian physics would predict. Either the current understanding of mechanics is incomplete, or there is more mass present somewhere in the galaxy that is not visible by any method that is currently employed. This invisible hunk of matter is what is termed as Dark Matter (DM).

Detailed observations of these rotation curves, along with measurements of other phenomena such as gravitational lensing by distant galaxies, galaxy clusters, and Cosmic Microwave Background (CMB) lead to the conclusion that, if the Dark Matter hypothesis is true, the amount of visible Baryonic matter in the universe is a mere 4\%. The remaining 96\% of the universe is composed of Dark Matter and Dark Energy.

Now it becomes important to address the question: what exactly is Dark Matter? 

Several extensions to the Standard Model, called Beyond Standard Model (BSM) theories, attempt to provide an explanation of these observed phenomena. Dark Matter hasn't been observed to interact directly through the electromagnetic force, and are thus invisible to current detectors. Consequently candidates for Dark Matter are called Weakly Interacting Massive Particles (WIMPs). In LHC experiments, events with WIMPs in the final state show up as an imbalance in the momentum in the plane transverse to the beam (referred to as \met throughout this thesis).

One such BSM theory postulates that these Dark Matter candidate particles may couple to Standard Model particles in interactions mediated by the Higgs boson. Fig \ref{fig:higgs} illustrates some of the possible processes for the production of the Higgs boson. The Higgs boson can then decay into invisible particles.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{higgs_production.png}
\caption{Feynman diagrams for the Standard Model production of the Higgs boson; VH: Higgs produced in association with a $W/Z$ boson (top left), ggF: gluon-gluon fusion (top right), VBF: vector boson fusion (bottom left), ttH: (bottom right). The Higgs boson then further decays into invisible DM particles.}
\label{fig:higgs}
\end{figure}

High energy collision experiments conducted at detectors are a method to experimentally investigate the predictions made by particle physics in a controlled manner. Several other kinds of detector experiments, both passive and active, investigate phenomena such as neutrino flavor oscillations and direct dark matter searches. The Large Hadron Collider (LHC), built and operated by CERN, is a proton-proton (and heavy ion) collider located in Switzerland and France, is the largest such collider in the world. It has provided invaluable data since commencing operations in 2008, providing experimental confirmation for phenomena such as the Higgs boson.

In this thesis, a closer look is taken at the VH channel, in particular ZH, where the Higgs boson decays invisibly into DM particles, and the $Z$ boson decays into a dilepton pair. The signature of such a process is \llM. A possible search in this channel would constitute stacking all known Standard Model processes that contribute to the \llM signal (making up the background) and look for excesses in data which will indicate the presence of non-Standard-Model processes. In this thesis, a closer look is taken at the \ZZ process, which constitutes the dominant SM background in the \llM final state. However, it is difficult to discriminate between the Standard Model \ZZ and $ZH\to l^+l^-+E_T^{miss}$, the process under consideration, because of the identical final state. Thus, an attempt is made to estimate it using alternate processes with clean signals. 

This chapter gives an overview of the Standard Model, its constituent matter particles, forces, and their interactions. It also delves into the shortcomings of the Standard Model, and introduces some ways in which Dark Matter is probed at the LHC. Chapter 2 describes the LHC, as well the ATLAS detector, where high energy collisions experiments are carried out. Chapter 3 discusses the theoretical aspects of investigating the \ZZ contribution, and details the approach taken, and chapter 4 presents the results obtained during the course of this thesis.

\section{The Standard Model}
The Standard Model is the name given to the theory of particles, fundamental forces, and interactions that govern the Universe. It describes three of the four forces: the electromagnetic, strong and weak forces. The Standard Model is formulated using the framework of Quantum Field Theories (QFT), which describe particles as excitations of an underlying field.

Throughout this thesis, the Lorentz-Heaviside system of units is used, such that $c=\hbar=1$ (where $c$ is the speed of light, and $\hbar=h/2\pi$ is the reduced Planck's constant), and thus these units do not show up in equations. Ref \cite{griff} is the reference textbook for much of this section.

\subsection{Matter and Forces}

In the Standard Model, matter is made up of fermions and bosons. Fermions are particles with half-integer spin, and interact through the exchange of gauge bosons, which have integer spin. All fundamental Standard Model fermions have spin 1/2. The Standard Model gauge bosons which mediate the interactions between particles have spin 1. The Higgs boson is a scalar boson, and has spin 0.

Figure \ref{fig:SM} shows a schematic representation of the elementary particles in the Standard Model.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{standard_model.png}
\caption{A schematic representation of the Standard Model\cite{SM} of particles. The table shows the three generations of fermions (classified as quarks and leptons) that are the building blocks of all known matter in the Universe, and bosons that mediate interactions, and are thus responsible for `forces'}
\label{fig:SM}
\end{figure}

All particles, except the neutral bosons (with no electromagnetic charge) have a corresponding antiparticle, which has the same properties, except with all its quantum numbers having an opposite sign.

Fermions are divided into two categories: leptons and quarks. There are six flavors of leptons and six flavors of quarks. All the quarks, and three flavors of leptons are electrically charged, and thus participate in electromagnetic interactions. Electromagnetic interactions are described by \textbf{Quantum Electrodynamics} (QED)\cite{QED}, a QFT. QED describes interactions in which two electrically charged particles exchange a photon. The photon is a spin-1 gauge boson, is electrically neutral, massless, and mediates electromagnetic interactions. Figure \ref{fig:qed_fund_vertex} shows the fundamental interaction vertex in QED, the interaction between two charged fermions and the photon.

\begin{figure}[h]
\centering
\includegraphics[width = 0.4\textwidth]{fundamental_vertex_qed.png}
\caption{Feynman diagram showing the fundamental interaction vertex in Quantum Electrodynamics. Charged fermions ($f$) interact via the exchange of a photon ($\gamma$), reproduced from Ref \cite{griff}.}
\label{fig:qed_fund_vertex}
\end{figure}

Quarks come in 6 flavors, which are divided into 3 `generations' having progressively higher masses; the up and down ($u$ and $d$) are first generation quarks, charmed and strange ($c$ and $s$) are second generation quarks, top and bottom, or formerly, truth and beauty, ($t$ and $b$) belong to the third genearation. Up-type quarks ($u$, $c$ and $t$) have an electric charge of +2/3$e$ (where $e$ is the unit of electronic charge, equal to $1.6\times 10^{-19}$ Coulombs), while down-type quarks have an electric charge of -1/3$e$. Quarks are the fundamental particle that form composite particles called Hadrons; bound states of $q\bar{q}'$ are called \textit{mesons}, and $qq'q''$ bound states are called baryons. Protons (bound state of $uud$) and neutrons (bound state of $udd$) are the most familiar examples of baryons.

Hadrons are bound together by the strong nuclear force. The strong interaction is described by the theory of \textbf{Quantum Chromodynamics} (QCD). In QCD, the strong interaction is mediated by gluons, which, like the photon, are massless spin-1 gauge bosons. However, unlike the photon, gluons don't carry electric charge. Instead, they carry an analogous color charge. There are three types of color charge, dubbed ``red'', ``green'' and ``blue''. These titles are arbitrary, and have been chosen under the heuristic that all naturally occurring states must be ``colorless''. Thus, a baryon must have three quarks such that red, green and blue occur in equal measures, or meson must have a quark and antiquark such that the color and anticolor cancel out. This leads to the implication that a color charged object cannot exist in isolation, a phenomenon known as confinement \cite{confinement}.

Quarks are the only fermions that interact through the strong force. However, gluons also carry color charge, and thus interact with quarks, and also with themselves. Gluons have several interesting properties; they are massless, have no distinct antiparticle, and are capable of self interaction, as shown in Figure \ref{fig:qcd_fund_vertex}. These properties lead to gluons splitting and radiating infinitely. Such interactions occurring in the vicinity of quarks result in the strength of the strong force changing inversely as a function of the distance between interacting quarks, i.e. quarks that are close to each other interact less strongly than quarks that are further apart. When quarks are separated, the potential energy arising from the strong force increases until it is energetically more favorable for the production of a quark-antiquark pair from the vacuum, screening the quarks, than it is to maintain the separation between them. This process, where a color-charged particle will cause other color-charged particles to be produced from the vacuum until the resulting bound state is color-neutral, is known as \textit{hadronization}, and results in single quarks or gluons from the hard interaction point forming ``jets" of several hadrons in the detector.

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\textwidth]{fundamental_vertex_qcd.png}
\caption{Feynman diagram showing the fundamental interaction vertex in Quantum Chromodynamics. reproduced from Ref \cite{griff}. The quark-quark-gluon vertex (left) shows the gluon mediating the interaction between two $up$ quarks, with their color content visible, to illustrate the conservation of color charge. Gluons are also capable of self-interacting, leading to three- or four-gluon interaction vertices (center, right).}
\label{fig:qcd_fund_vertex}
\end{figure}

Confinement explains why quarks or gluons have never been observed, and why the strong-interaction is short ranged despite being mediated by the massless gluons. The property of strongly interacting particles, that at small distances of the order of less than a femtometer they basically act as free particles, is known as \textit{asymptotic freedom}. At these scales, quarks and gluons may be treated individually rather than as a bound state.

The other family of fermions, leptons, also form three generations. Each generation consists of an electrically charged lepton, and its corresponding electrically neutral neutrino; i.e. electrons ($e$), muons($\mu$) and tauons(($\tau$)) (in increasing order of mass), which have an electric charge of -1$e$, and their correspondingly flavored neutrinos ($\nu_e$, $\nu_{\mu}$ and $\nu_{\tau}$). Neutrinos, assumed by the Standard Model to be massless, have been observed to have masses \cite{nu1,nu2,nu3} which are known to be small, but have not been measured. Tau leptons are the heaviest at 1.78 GeV, and decay rapidly, having a mean lifetime of $2.9\times 10^{-13}$ s in their rest frame. Muons have a mass of 106 MeV, about 200 times heavier than that of the electrons (0.511 MeV). Muons, however, decay with a mean lifetime of $2.2 \mu$s, which is long compared to the time scales in collider experiments, and are stable enough to pass through the detectors intact.

All leptons interact through the weak nuclear force. Neutrinos especially only participate in Standard Model interactions through the weak interaction, thus making them difficult to detect. Collider experiments don't even attempt to detect neutrinos, instead inferring their presence through momentum imbalance (as they are invisible to the detectors). 

There are two kinds of weak interactions; charged-current and neutral-current interactions. The $Z$ boson, an electrically neutral, spin-1, massive gauge boson, mediate neutral-current weak interactions. Such interactions are analogous to electromagnetic interactions. However, there are notable differences. The $Z$ boson is massive (at 91 GeV, it is one of the largest known masses in the Standard Model), whereas the photon is massless. This limits the range of the interaction, as the $Z$ boson decays, and has a mean lifetime of the order $10^{-25}$s. The fact that the $Z$ boson is massive gives it longitudinal polarization modes\cite{quarks_and_leptons} as well, which the photon does not possess. The $Z$ boson also mediates interactions between neutrinos, which the photon does not as neutrinos are electrically neutral. Also, weak interactions do not respect Parity (P) symmetry. The coupling strengths of the $Z$ boson to fermions depends on their flavor and helicity, with left-handed fermions and right-handed anti-fermions coupling more strongly than right-handed fermions and left-handed anti-fermions. In fact, the $Z$ boson doesn't couple at all to right-handed neutrinos. However, neutral-current interactions still respect combined charge and parity (CP) symmetry.

A slight digression to define helicity is warranted at this point. Helicity is defined as the projection of a particle's spin vector onto its momentum vector. If the helicity is positive, the particle is considered to be right-handed. If it is negative, the particle is considered to be left-handed.

Charged-current interactions are mediated by the $W^+$ and $W^-$ bosons, which carry an electrical charge. Charged-current interactions do not respect parity symmetry either, and are in fact maximally parity violating; the $W$ bosons only couple to left-handed fermions and right-handed anti-fermions. Thus, with neutrinos only interact weakly, and neither the $Z$ nor $W$ bosons interact with right-handed neutrinos, there doesn't appear to be a reason for right-handed neutrinos to exist within the Standard Model. Charged-interactions do no respect the combined CP symmetry either, unlike neutral-current interactions. This CP violation occurs at a small but measurable rate. The first evidence of CP violation was provided by the Fitch-Cronin experiment \cite{cronin_fitch}, in 1964, in the neutral kaon system, before the theory of the weak force was even completely formulated. After its formulation, it was apparent that CP violations arise from a complex phase in Cabibbo-Kobayashi-Maskawa (CKM) matrix \cite{CKM}, a unitary $3\times 3$ matrix shown in Figure \ref{fig:CKM matrix}. Charged-current weak interactions are capable of coupling quarks from different generations, the degree of which is given by the CKM matrix. A complex phase in the elements of this matrix is what gives rise to CP violation.
\begin{figure}[H]
\[
\begin{bmatrix}
d'\\
s'\\
b'
\end{bmatrix}
=
\begin{bmatrix}
V_{ud} & V_{us} & V_{ub}\\
V_{cd} & V_{cs} & V_{cb}\\
V_{td} & V_{ts} & V_{tb}
\end{bmatrix}
\begin{bmatrix}
d\\
s\\
b
\end{bmatrix}
\]
\caption{The Cabibbo-Kobayashi-Maskawa matrix that shows the degree of mixing among the quark flavors. Charged-current weak interactions, mediated by the $W$ bosons, allow coupling of quarks between two generations, causing the eigenstates of the weak interaction $d'$, $s'$ and $b'$ to be superpositions of the observable mass eigenstates $d$, $s$ and $b$.}
\label{fig:CKM matrix}
\end{figure}
CP violation has subsequently been confirmed in several meson decays\cite{CP1,CP2,CP3,CP4,CP5,CP6} since then.

Continuing the analogy between the electric charge and the color charge to the weak interaction as well, the quantum number for the weak interaction is the three-component weak isospin, $T^i$. It is typically defined such that $T^3$ is the measure component, and may be treated as the weak charge. Weak isospin is conserved in electromagnetic, strong and fermion-fermion weak interactions, however interactions involving the Higgs field change this isospin of particles. Electric charge $Q$, however, is always conserved, and is a combination of the weak isospin $T^3$ and the weak hypercharge (the quantum number corresponding to the $U(1)$ gauge symmetry) $Y_W$.
$$
Q = T^3 + \frac{1}{2}Y_W
$$

The connection between the electromagnetic and weak forces, and the similarities between weak neutral-current interactions and QED hint at unification, and indeed the Standard Model unifies the them into a single \textit{electroweak} force. The differences between electromagnetic and weak interactions, such as the mass of weak gauge bosons, arise from electroweak symmetry breaking.

The strong, weak and electromagnetic forces can be described by the $SU(3)\times SU(2)\times U(1)$ local gauge symmetry group, where the $SU(3)$ symmetry group describes the strong interaction, and the electroweak interactions are based on the $SU(2)\times U(1)$ symmetry group. There are 8+3+1 generators associated with this model, each generator corresponding to a vector boson. Thus, there exist 8 gluons for the 8 generators of the $SU(3)$ group. The interaction of the scalar Higgs field with the vector fields $W^+$, $W^-$, $W^0$ and $B$ causes the spontaneous breaking of the $SU(2)\times U(1)$ symmetry, resulting in 3 massive and one massless gauge boson. It also implies the existence of a neutral scalar boson, known as the Higgs boson, which was discovered in July 2012\cite{Higgs}. The 3+1 generators of $SU(2)\times U(1)$ correspond to the $W^+$,$W^-$ and $Z$ bosons, massive vector bosons , and the massless vector boson $\gamma$ (photon).

\section{Inadequacies of the Standard Model}
Despite its immense success, the Standard Model does not paint a complete picture of everything that we observe. It does not account for several phenomena that are experimentally observed, such as:
\begin{itemize}
\item Gravity: The Standard Model does not include gravity. If, analogous to the other forces, a 'graviton' is introduced into the Standard Model as an extension, it does not describe what is observed experimentally. In fact, the Standard Model is incompatible with general relativity\cite{grav_inc}.

\item Dark Matter and Dark Energy: Cosmological observations, such as galaxy rotation curves, do not match predictions based on the visible amount of mass in the universe. A fit with the observations predicts additional invisible matter, called Dark Matter\cite{DM_inc}. Similarly, the universe is expanding at an accelerating rate, which hints at the existence of Dark Energy\cite{DE}. The Standard Model does not account for exotic matter such as these. In fact, the Standard Model only accounts for about 4\% of the content of the universe \cite{Planck,DM_comp}.

\item Neutrino masses: Neutrinos are assumed to be massless in the Standard Model. However, neutrino oscillations have recently been observed\cite{neutrino2}, which is only possible if neutrinos have mass\cite{neutrino_mass}.

\item Matter-antimatter asymmetry: According to the Standard Model, matter and antimatter should be created in equal quantities. However, the universe appears to have a preference for matter, indicating that in its initial state of the universe, this symmetry was broken\cite{Baryon_Asymmetry}.

\item Hierarchy problem\cite{hierarchy1,hierarchy2,hierarchy3,hierarchy4}: Quantum corrections to the Higgs mass are divergent, and force it to be very large. However, experiments show a surprisingly small number for the Higgs mass, at 125 GeV. There appear to be some extraordinary fine tuned cancellations that make this mass so small.
\end{itemize}

The Standard Model is incomplete, and thus requires modifications or additions to it, which are collectively called Beyond Standard Model (BSM) theories.

\subsection{Beyond the Standard Model}
Several extensions to the Standard Model have been proposed that attempt to address some of its inadequacies. 

Supersymmetry (SUSY) attempts to reconcile gravity with the SM, and adds another symmetry to the Standard Model, predicting the existence of $supersymmetric$ partners, called sparticles, to Standard Model particles. For example, sleptons are supersymmetric partners to the corresponding leptons, and differ by spin 1/2. SUSY would also resolve the hierarchy problem by ensuring that the divergences would cancel out at all orders in the perturbation expansions, if the superpartners have mass near the electroweak scale (broadly, between 100 and 1000 GeV).

The observation of neutrino oscillations imply that neutrinos have mass, however, these observations can only reveal the mass difference between the different neutrino flavors. The absolute mass of the neutrinos has been constrained to have an upper limit of 2 eV, much smaller than the lightest SM particles, by precision measurements of tritium decays. To incorporate neutrino masses, an extension to the Standard Model, the see-saw mechanism, introduces right handed neutrinos and couples them to left-handed neutrinos with a Dirac mass term.

Both SUSY and the addition of a sterile right-handed neutrino to the SM are extensions that provide candidates for Dark Matter. These candidates are known as Weakly Interacting Massive Particles (WIMPs). They do not interact electromagnetically, and are thus invisible to most detectors.

\subsection{Dark Matter}
Cosmological observations of galaxies made over the decades, such as the velocity curves of galaxies (called galaxy rotation curves) indicate an anomaly; the stars in the arms of spiral galaxies appear to move faster than what would be expected from Keplerian relations, using the visible mass from the galaxies. Figure \ref{fig:grc} shows the two rotation curves, expected and observed, of NGC 6503, a field\footnote{Field galaxies do not belong to a large cluster, and are thus gravitationally isolated}  spiral galaxy.\cite{galaxy}
\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{GRC.jpeg}
	\caption{Velocity of stars in NGC 6503, a field spiral galaxy, as a function of radial distance from the center of the galaxy\cite{galaxy}. The 'Luminous' curve is what would be expected from the visible mass, but what is observed is much higher, indicating excess invisible matter.}
	\label{fig:grc}
\end{figure}
Either the current understanding of Newtonian Mechanics is incomplete, or there is additional mass that is not visible which is contributing to the mass term in Newton's equation. This invisible mass is what is termed as Dark Matter. Ergo, Dark Matter appears to interact gravitationally, but not electromagnetically, with visible (Standard Model) matter. It is possible that Dark Matter is made up of and exotic and hitherto undiscovered kind of matter, and searches are underway at the LHC to look for Dark Matter via its interactions with the Standard Model.

There is additional cosmological evidence supporting Dark Matter, such as gravitational lensing of distant galaxies, structure formation in the early universe, anisotropy in the cosmic microwave background, etc.

\subsubsection{Dark Matter searches at the \hyperref[ch:LHC]{Large Hadron Collider}}

As Dark Matter does not interact electromagnetically, any Dark Matter particles produced in collider experiments will be invisible to detectors at the LHC. Thus, in event reconstruction, such events are expected to be marked by a significant imbalance in transverse momentum (\met). Currently, Dark Matter searches are conducted at the LHC\cite{DM_searches}. Dark Matter particles are denoted by $\chi$.
\begin{itemize}
\item Mono $\chi$ searches : These searches look for the production of a Standard Model particle in association with \met. Figure \ref{fig:Mono_X} shows the Feynman diagrams for the Mono-X processes.
	\begin{itemize}
	\item Mono-jet : In theory, it is possible to produce Dark Matter particles in association with one or more QCD jets from initial state radiation. Thus mono-jet searches look for one or more jets in events with large \met.
	\item Mono-V : In a similar manner to mono-jet searches, a mono-V search looks for a single vector ($\gamma,W$ or $Z$) boson. If DM particles couple directly to a pair of gauge bosons, this may be the dominant mode of DM production.
	\item Mono-Higgs : It may also be that a single Higgs boson is produced in association with \met. Such events would be characterised by a $H\to\gamma\gamma$ or $H\to bb$ final state.
	\end{itemize}
	
\begin{figure}[H]
\centering
\includegraphics[width=0.65\textwidth]{Mono_X.png}
\caption{Feynman diagrams for mono X processes, showing mono-jet production (top) induced by gluons (top left) and quarks (top right) \cite{mono_j} where the mediator X can be a scalar, pseudo-scalar, vector or axial-vector particle; mono-V (bottom left) \cite{mono_V}; and mono-higgs (bottom right) \cite{mono_h}, where h is the Standard Model Higgs boson with mass 125 GeV.}
\label{fig:Mono_X}
\end{figure}

\item DM+top : If DM particles couple predominantly to heavy quark flavors, a search for a top quark pair is a promising direction to head in.
\item Invisible Higgs :  If the mass of the DM particles is less than half the mass of the Higgs boson, it may be possible that the DM particles couple to the Standard Model via the Higgs boson, i.e $H\to\chi\chi$ processes. The main methods of Standard Model Higgs production are shown in Figure \ref{fig:higgs}.
	\begin{itemize}
	\item Vector boson fusion (VBF): In VBF processes, the Higgs is produced from the interaction of two vector bosons.
	\item Production of Higgs in association with a massive vector boson (VH) : This mechanism, together with VBF are the most important methods of Higgs production in invisible Higgs searches. Such events can be recognised with a large imbalance in transverse momentum, as well as the decay products of the vector boson.
	\item Gluon gluon fusion (ggF) : It is also possible for the Higgs to be produced from the interaction of gluons.
	\end{itemize}
\end{itemize}

This thesis investigates the Standard Model background to the $ll+$\met signal with respect to the production of an invisible Higgs in association with a leptonically decaying gauge boson. Chapter \ref{ch:LHC} gives an overview of the Large Hadron Collider, the ATLAS detector, and details the event topology. Chapter \ref{ch:theory} address the theoretical framework of this thesis.

\section{Proton-Proton Collisions}
Theory and experiment go hand in hand. It is necessary to have experimental confirmation of theoretical predictions, while at the same time, new or unexpected experimental observations prod theories along in the right direction. There are a number of parameters in theory that are unknown, and thus, experiments provide measurements of such parameters. 

The work in thesis was conducted with the ATLAS Collaboration. ATLAS, being one of the detector experiments at the LHC, probes proton-proton collisions. This section attempts to give an overview of the physics of proton-proton collisions, which are one of several ways to probe particle interactions at high energy scales.

Protons are baryons, bound states of three quarks ($uud$), known as the valence quarks. However, the mass of the quarks put together is only about 1\% of the mass of the proton (938 MeV). The remainder of the proton mass originates from the QCD binding energy, which is the exchange of virtual gluons. The constituents of the proton, namely the quarks and gluons, are collectively known as partons. Roughly half the total momentum of the proton is carried by the gluons. Now, the number of gluons is not conserved, and they are capable of self interaction, the gluon structure within a proton is not constant. Gluons produce virtual $q\bar{q}$ pairs that again annihilate on timescales of the order $t_{virt}=1/\Delta E$.

\chapter{The Large Hadron Collider}\label{ch:LHC}
The Large Hadron Collider (LHC) is a circular collider experiment located in France and Switzerland. It was built by the European Council for Nuclear Research (CERN) in collaboration with over 10000 scientists from all over the world, between 1998 to 2008, when it began its operation and started collecting data. It is the world's largest, most powerful particle collider, focusing primarily on proton-proton collisions, but also conducts heavy ion collision experiments as well. It is the largest single machine in the world.

The goal of the LHC is to experimentally test predictions made by theories of particle physics, and look for evidence of new physics. It has enjoyed remarkable successes, such as the discovery of the Higgs Boson in 2012.

The LHC houses seven experiments: ATLAS and CMS are the largest, general-purpose detectors that focus on the Higgs boson, and searche for evidence new physics. ALICE is a heavy ion collider experiment that studies quark-gluon plasma, while LHCb studies CP violation. In addition, three smaller experiments, TOTEM, MoEDAL and LHCf are much smaller and used for highly specialized research.

\section{History}
The concept of the LHC was officially recognized during a workshop held by CERN and the European Committe for Future Accelerators (ECFA) during 21-27 March 1984. The tunnel that would later house the LHC was constructed between 1983-1988 to house the Large Electron-Positron Collider. The tunnel is 27 km in circumference, and located underground, underneath the Swiss-France border.

The construction of the LHC was completed in 2008, and on the 10th of September 2008, a beam of protons was successfully steered around the 27 kilometer ring of the LHC for the first time. After initial lower energy collision runs in 2009, the first 7 TeV center of mass energy collisions were recorded by the ATLAS detector in 2010.

Since then, the LHC has gone on to make remarkable discoveries. In May 2011, ALICE reported the creation of quark-gluon plasma, and extremely dense state of matter. On July 4th 2012, CERN reported the observation of a particle having mass 125 GeV, consistent with the properties of the Higgs boson. Both ATLAS and CMS teams comfirmed this discovery with a statistical significance of 5 sigma, meeting the requirements to announce a new particle. The LHCb experiment observed multiple exotic hadrons, such as pentaquarks.
\vfill

\section{Design}
\begin{figure}[H]
\centering
	\includegraphics[width=0.9\linewidth]{Cern_accelerator_complex.png}
	\caption{The CERN accelerator complex showing the various components of the Large Hadron Collider experiment, such as the linear accelerators, the accelerating synchrotrons, the main ring, and the four detectors, where the protons or heavy ions are collided.}
		\label{fig:LHCring}
\end{figure}
\textbf{Note: This section is, with minor rephrasing, taken from Wikipedia. I have to change the wording better or it'll trip plagiarism checks. For now, this section is so I have an idea of the layout and matter of this chapter.}

The LHC is contained in a circular tunner 26.7 km in circumference, located at a depth ranging between 50 and 175 meters underneath the Swiss-France border. The tunnel contains two parallel beam pipes. Each of the two beam pipes house a beam of protons (or heavy ions), which travel in opposite directions, until they are made to collide at 4 points where the beam pipes intersect. The beams are kept on their path by an array of 1232 superconducting dipole magnets. An additional 392 superconducting quadrupole magnets focus the beams to maximize the chance of interaction. Magnets of higher mulitpole orders are used to correct deviations in the field geometry. In total, the LHC uses about 10000 superconducting magnets. In order to keep these magnets at superconducting temperatures (-271.25$^\circ$ C), about 96 tonnes of helium-4 coolant is required, thus making the LHC the world's largest cryogenic facility at liquid helium temperature.

The LHC currently imparts an energy of 6.5 TeV per proton in the center of mass frame. This corresponds to velocity of about 0.999999990 c, only 3.1 m/s slower than the speed of light. At these speeds, a proton can cover the 27 km circumference of the main LHC ring in only 90 microseconds.

The colliding protons are prepared for collisions by a sequence of systems that progressively increase their energy. The linear particle accelerator, LINAC 2 generates 50 MeV protons, which are fed into the Proton Synchrotron Booster (PSB). The PSB accelerates the protons to 1.4 GeV, and from there the protons are injected into the Proton Synchrotron (PS), where they are accelerated to 26 GeV. The Super Proton Synchrotron (SPS) then incereases their energy further to 450 GeV, before the protons are injected into the main ring. 

Instead of a continuous beam, the protons are accumulated into bunches and accelerated to their peak energy at 6.5 TeV over a period of 20 minutes, during which the magnetic field of the superconducting dipole magnets is increased from 0.54 to 7.7 Teslas, and circulated for up to 24 hours while collisions occur at the four intersection points. Each proton bunch consists of approximate 115 billion protons in each bunch, with about 2,800 bunches at a time. The interactions happen at intervals 25 nanoseconds apart. Figure \ref{fig:LHCring} shows the layout of the LHC main ring, LINAC2, PSB, PS and SPS.

While LHC experiments mainly consist of proton proton collisions, for shorter times of the order of a month per year, heavy ion collisions, such as lead, are also conducted. The lead ions are first accelerated by the LINAC3 linear accelerator, an the Low Energy Ion Ring (LEIR) is used as an ion storage and cooler unit. These ions are further accelerated by the PS and SPS before being injected into the LHC main ring, where they are imparted an energy of 2.3 TeV per nucleon. The ALICE experiment is where these ions collide, in order to investigate quark-gluon plasma.

\section{The ATLAS experiment}
The ATLAS (A large ToroidaL ApparatuS\footnote{Sometimes, scientists are just bad at anagrams}) detector is located at one of the four beam intersection points. It is a multipurpose experiment which, after the discovery of the Higgs boson in 2012, focuses on searches for new physics, such as supersymmetry, or dark matter. The experiment is a collaboration between around 3000 physicists from over 175 institutions in 38 countries.

The ATLAS detector is a large apparatus with a cylindrical geometry, forward-backward symmetry, and nearly 4$\pi$ solid angle coverage. It is 46 meters long, 25 meters in diameter and weight 7000 tonnes. The detectors consists of concentric cylindrical layers around the interaction point, where the proton beams collide. Broadly, it consists of the  Inner Detector, the electromagnetic (EM) and hadronic calorimeters.

\textbf{Note: Incomplete. I will complete the description of the detector, and the dimensions of the components. I will also discuss proton proton collisions, followed by the detection of particles at different components, and then triggers and data collection.}

\chapter{Theoretical Aspects}\label{ch:theory}
\section{Invisible Higgs in association with a Z boson - ZH}
In this thesis, the production of the Higgs boson, in association with a $Z$ boson is considered. In this model, as shown in Figure \ref{fig:HZ}, the Higgs boson mediates the interaction between Dark Matter particles and Standard Model particles, and the $Z$ boson decays into a lepton-antilepton pair. As Dark Matter is invisible to current detectors, this process results in the $ll+$\met signature.
\begin{figure}[H]
\centering
	\includegraphics[width=0.5\linewidth]{HZ.png}
	\caption{Feynman diagram showing the associated production of a Higgs boson with a Z boson. The Higgs boson decays to two invisible DM particles and the Z boson decays leptonically, resulting in the $ll+ E_T^{miss}$ signature.}
		\label{fig:HZ}
\end{figure}
The main Standard Model background processes for the $ll+$\met final state are \ZZ, $WZ\to lll\nu$, $WW\to l\nu l\nu$, $Z+$jets and $W+$jets. 

\subsection{Selection Criteria}
The selection criteria used in Ref \cite{ZH_ATLAS} is applied for the analysis reported in this thesis as well. The search is conducted on events with a $ll+$\met final state, having a pair of high $p_T$ electrons ($ee$) or muons ($\mu\mu$), and large missing transverse momentum. Events with extra leptons or $b$-jets are removed to reduce backgrounds, and the requirement of a boosted $Z$ boson back to back with the missing tranverse momentum vector is imposed.

Electron candidates are selected based on the ATLAS tracker and EM calorimeter dimensions, with $p_T > 7$ GeV and pseudorapidity $|\eta| < 2.47$. Similarly, muon candidates are required to have $p_T > 7$ GeV and pseudorapidity $|\eta| < 2.5$. 
%Electrons and muons are required to satisfy a set of identification criteria, referred to as the "medium" criteria \cite{e_medium, mu_medium}.
To suppress cosmic-ray and non-prompt contributions, the longitudinal impact parameter of the leptons, $|b|<0.5$ mm, and the transverse impact parameter divided by its error must be less than 5 for electrons and 3 for muons. To remove jets misidentified as leptons, or leptons from $b$-hadron decays, 'loose' isolation criteria \cite{loose1,loose2} are applied. To maintain a uniform efficiency of 99\% for signal leptons, the isolation selection varies as a function of $p_T$ .

%Jets are reconstructed with the anti-$k_t$ algorithm \cite{antikt} with the radius parameter R = 0.4 \cite{cell_cluster,jet_calib,fast_jet}. Candidate jets must have a $p_T > 20$ GeV and $|\eta|<4.5$

\textbf{Need to add some more information about the selection criteria, with references.}

Table \ref{table:event_selection} summarises the event selection criteria in the $ll+$\met search, as shown in \cite{ZH_ATLAS}.

\begin{table}[H]
\centering
\begin{tabular}{c c}
\hline
\hline
& Selection criteria\\
\hline
Two leptons & Two opposite-sign leptons, leading (subleading) $p_T>$ 30 (20) GeV \\
\hline
Third lepton veto & Veto events if any additional lepton with $p_T>7$ GeV\\
\hline
$m_{ll}$ & 76$<m_{ll}<$106 GeV\\
\hline
\met and \met$/H_T$ & \met$>$ 90 GeV and \met$/H_T >$ 0.6\\
\hline
$\Delta\phi(\vec{p}_T^{ll},\vec{E}_T^{miss})$ & $\Delta\phi(\vec{p}_T^{ll},\vec{E}_T^{miss})>2.7$ radians\\
\hline
$\Delta R_{ll}$ & $\Delta R_{ll}<1.8$\\
\hline
Fractional $p_T$ difference & $\left| p_T^{ll} - p_T^{miss,jets}\right|/p_T^{ll}<0.2$\\
\hline
$b$-jet veto & $N$($b$-jets) = 0 with $b$-jet $p_T>20$ GeV and $|\eta|<2.5$\\
\hline
\hline
\end{tabular}
\caption{Event selection criteria in the $ll+$\met search as shown in Ref \cite{ZH_ATLAS}}
\label{table:event_selection}
\end{table}

\subsection{Results of the ZH search}
As discussed in Ref \cite{ZH_ATLAS}, an upper limit of 67\% is placed on the Higgs$\to$ DM branching ratio at the 95\% confidennce level. The dominant source of background is the \ZZ process, contributing $\approx 60\%$ of the background. $WZ\to lll\nu$ events, where the $W$ boson decays into a electron or muon that escapes detection, account for 25\% of the total background. $Z(\to ll)+$jets process with misreconstructed \met contributes to about 8\% of the total background, and non-resonant-$ll$ processes, consisting of $t\bar{t}$, $Wt$, $WW$ and $Z\to\tau\tau$ production contribute similarly. $W+$jets, $VVV$, and $t\bar{t}V(V)$ backgrounds contribute to a minor extent ($<1\%$).

Figure \ref{fig:ZH_results} shows the observed \met distribution in the $ee$ and $\mu\mu$ channels, compared to the signal and background predictions.
\begin{figure}[h]
\centering
		\includegraphics[width=0.9\textwidth]{ZH_results.png}
		\caption{The observed \met distributions in the $ee$ (left) and $\mu\mu$ channels, compared to the signal and background predictions. The total statistical and systematic uncertainty on the background predictions are shown by the error bands. The Standard Model background predictions are stacked. The $ZH\to ll+$ invisible signal distribution is shown with $B_{H\to inv}=0.3$, and the simulated DM distribution is also scaled (with a factor of 0.27) to the best-fit contribution \cite{ZH_ATLAS}.}
		\label{fig:ZH_results}
\end{figure}

This thesis focuses on the $ZZ$ background; its estimation and the uncertainty associated with it. In Ref \cite{ZH_ATLAS}, the $ZZ$ background is estimated from simulation, with a total uncertainty of 10\%.



\section{Background estimation: ZZ}
It is difficult to identify \ZZ events, as their final state is identical to that of $ZH\to ll+$\met. Thus, the contribution of \ZZ is currently estimated using simulation. Figure \ref{fig:ZZ} shows the Standard Model production of $q\bar{q}\to ZZ$ and $gg\to ZZ$. One of the $Z$ bosons decays leptonically (into $e^+e^-$ or $\mu^+\mu^-$), while the other $Z$ boson decays into neutrinos ($\nu\bar{\nu}$). Neutrinos are very weakly interacting, and thus are invisible to the detectors at the LHC, and thus result in events with missing transverse momentum.

\begin{figure}[H]
\centering
		\includegraphics[width=0.7\textwidth]{ZZ.png}
		\caption{Feynman diagram showing $ZZ$ production, in the s-channel (a) and t-channel (b) induced by $q\bar{q}$, and induced by gluons (c).}
		\label{fig:ZZ}
\end{figure}

It is possible to estimate the \ZZ using $ZZ\to llll$ data. However, the precision of this process is statistically limited. The branching fraction $Z\to ll$ for one flavor of lepton ($e/\mu$) is $\approx 3.4\%$, and $Z\to\nu\nu$ is 20\%. 
\begin{align}
BR(ZZ\to llll) &= (2\times 0.034)\times(2*0.034) = 0.00462\\
BR(ZZ\to ll\nu\nu) &= (2\times 0.034)\times(0.2)\times 2 = 0.0272
\end{align}
Thus, branching fraction of $ZZ\to llll$($\approx$0.46\%) compared to \ZZ (2.7\%), which is about 6 times higher. The low branching fraction of $ZZ\to llll$ limits the statistics.

Motivated by an analysis using $\gamma+$jets to estimate $Z+$jets\cite{gamma_jet}, an alternative method to estimate \ZZ is to look at the \Zg process. Figure \ref{fig:Zg} shows the leading order diagrams for the production of $Z\gamma$, where the $Z$ boson further decays leptonically. Figures \ref{fig:Zg}.a, b and c are similar to the production of $ZZ$, with a photon instead of one of the $Z$ bosons. The main differences in the two processes are the couplings of the photon and $Z$ boson to the quarks, and the fact that photons are massless, whereas the $Z$ boson is massive. 

Figure \ref{fig:Zg}.d gives the $ll\gamma$ final state, however, the photon is radiated off of a final state lepton, i.e. Final State Radiation (FSR). This process must be suppressed, which can be done by imposing a mass window on the reconstructed mass of the two leptons to be within 15 GeV of $Z$ boson mass shell.

\begin{figure}[H]
\centering
		\includegraphics[width=0.8\textwidth]{Zg.png}
		\caption{Feynman diagram showing $Z\gamma$ production, in the s-channel (a) and t-channel (b) induced by $q\bar{q}$, and induced by gluons (c). Diagram (d) shows a similar final state, but the photon is radiated off of a final state lepton (Final State Radiation).}
		\label{fig:Zg}
\end{figure}

At high $Z $ boson transverse momentum, the \Zg process should be kinematically similar to \ZZ, as the mass of the $Z$ boson will be negligibly small compared to its $p_T$. The \Zg signal is also pure, and has a BR$\times\sigma$ as compared to \ZZ. Thus, it should be possible to use \Zg data to estimate the contribution of \ZZ in regions of high $Z$ boson $p_T$.

\section{Transfer factor R}
To estimate the background, a transfer factor $R(p_T)$ is introduced, defined to be the ratio of the cross sections of \ZZ to \Zg as a function of the $p_T$.
\begin{equation}
	R(p_{T}) = \frac{\sigma_{ZZ}(p_{T})}{\sigma_{Z\gamma}(p_T)}
\end{equation}
With the two processes being kinematically similar at high $p_T$, $R$ depends on the coupling of the $Z$ and $\gamma$ to quarks. It would be expected to reach a constant value at high $p_T$ that can be determined theoretically. In the following paragraph, an attempt is made to obtain a simple approximate calculation of $R$ from the contribution of $qq$ process.

The photon - quark and $Z$ boson - quark couplings in the Standard Model are given by,
\begin{equation}
	-ieQ_q\gamma^{\mu} \hspace{1 cm} \text{and} \hspace{1 cm}\frac{-ie}{2 \sin\theta_W \cos\theta_W}\gamma^{\mu}(v_q - a_q\gamma_5)
\end{equation}
respectively, where $Q_q,v_q$ and $a_q$ are respectively the electric, vector and axial neutral weak couplings of the quarks, and $\theta_W$ is the weak mixing angle. There is a contribution due to the $Z$ mass which appears in the internal propagators and phase space integration. This contribution becomes less important in the $p_T(\gamma)\gg M_Z$ region.

Thus, the leading order contributions from $q\bar{q}\rightarrow ZZ$ and $q\bar{q}\rightarrow Z\gamma$ are shown in Equation \ref{eq:theory_R}.
\begin{equation}
\begin{split}
	\sigma(q\bar{q}\rightarrow ZZ) &\propto \frac{1}{2}\frac{e^4\{(v_q^2 + a_q^2)^2 + 4v_q^2a_q^2\} }{16\sin^4\theta_W\cos^4\theta_W}\\[1.5ex]
	\sigma(q\bar{q}\rightarrow Z\gamma) &\propto \frac{e^2Q_q^2(v^2_q + a^2_q)}{4\sin^2\theta_W\cos\theta_W}
\end{split}
\label{eq:theory_R}
\end{equation}
The $u$ and $d$ quarks present in a $pp$ collision have different coupling strengths to the $Z$ boson as stated in Ref\cite{Z_coupling}, their relative contributions are accounted for using Equation \ref{eq:u_d_contrib}
\begin{equation}
R = \frac{\sigma(u\bar{u}\rightarrow ZZ)\langle u\rangle + \sigma(d\bar{d}\rightarrow ZZ)\langle d\rangle}{\sigma(u\bar{u}\rightarrow Z\gamma)\langle u\rangle + \sigma(d\bar{d}\rightarrow Z\gamma)\langle d\rangle}
\label{eq:u_d_contrib}
\end{equation}
Using the vector and axial couplings of the $Z$ boson to $u$ and $d$ quarks\footnote{Vector and Axial couplings of Z to $u$ and $d$ quarks: $v_u = 0.18, a_u = 0.50, v_d = -0.35, a_d = -0.514$}, assuming $\langle d \rangle/\langle u\rangle = 0.5$ and setting $\sin^2\theta_W = 0.2315$, $R\approx 1.28$ for the dominant $q\bar{q}$ interaction. This approximate calculation has not been performed for gluon induced channels, as they involve loops and require a more involved calculation.

This transfer factor $R$ may be used with $Z\gamma$ data to estimate the contribution of $ZZ$ with reasonable accuracy at high $p_T$. To improve precision, it is necessary to estimate the theoretical uncertainties on the transfer factor $R$.

\section{Theoretical Uncertainties}
In this study, the following sources of theoretical uncertainties are studied.
\begin{itemize}
\item Missing higher order corrections: Contributions due to higher order QCD corrections cannot be calculated to arbitrarily high order, as it gets progressively more computationally expensive. Thus, this study is limited to Next to Leading Order (NLO), and further corrections are accounted for by varying the factorization and renormalization scales.

\item Uncertainties associated with Parton Distribution Functions: A proton is a baryon, and according to the Parton model \cite{parton_model} and is composed of three valence quarks, and several gluons. Thus, proton-proton collisions, such as in the experiments conducted at the LHC, involve the interaction of these composite quarks and gluons (partons) at very high energies. These partons carry a fraction of the proton momentum. Parton Distribution Functions (PDFs) represent this fraction of proton momentum carried by partons as probability distributions. Owing to the non-deterministic nature of this fact, this study attempts to account for this uncertainties as PDF uncertainties.

\item Photon Fragmentation Uncertainties: In the \Zg process, the signal includes a photon. However, while reconstructing the event, soft photons, or photons resulting from other fragmentation processes may be encountered. To ensure that the photon is indeed prompt, it is required to be isolated from hadronic activity (such as pion decays). This isolation is implemented experimentally in different ways. The uncertainty associated with the implementation of this isolation is estimated as photon fragmentation uncertainties.
\end{itemize}

Each of these sources are explained further in their respective sections in Chapter \ref{ch:Results}.

\section{Approach}
Thus far, it has been established that a viable method to estimate the $ZZ$ background contribution to the $ll+$\met final state is to use $Z(\to ll)\gamma$ data, where the photon models the Standard Model invisible $Z$ boson. A transfer factor $R$ is introduced as the ratio of the cross sections of \ZZ to \Zg. In the high $Z$ boson $p_T$ region, the two processes are kinematically similar, therefore the curve of the transfer factor $R$ as a function of $p_T$ is expected to approach a constant value. This transfer can be used to estimate to the contribution of \ZZ from \Zg data.

This thesis estimates the theoretical uncertainties on the transfer factor. The \ZZ and \Zg cross sections are obtained from MCFM, a femtobarn level matrix element generator. Varying the input parameters provided in the MCFM input file, the theoretical uncertainties are estimated.

%\section{Theoretical aspects}
%
%The Standard Model is based on the formalism of quantum field theories (QFTs), in which particles are intepreted as excitations of underlying fields.
%
%\subsection{Quantum Electrodynamics}
%Quantum Electrodynamics (QED) is the relativistic quantum field theory of electromagnetism. It encompasses all particles having a charge (which includes all the quarks and charged leptons, and their charged composite particles), and the photon as the mediator of interactions between these.
%
%Quantum Electrodynamics is extended to describe the electroweak theory, which includes neutrinos, and the $W$ and $Z$ bosons as mediators of interactions.
%
%\subsection{Quantum Chromodynamics}
%Quantum Chromodynamics (QCD) is the quantum field theory of strong interactions. It describes particles that have color charge (such as quarks, and their composite particles),and is mediated by gluons.
%
%QCD has some interesting properties. For example, the force between two color charges remains constant, a phenomenon known as $color\ confinement$. Thus, separating quarks requiring increasing amounts of energy. Eventually it becomes energetically favorable to simple create a quark-antiquark pair from vacuum, forming color neutral hadrons. Another interesting property is that the strength of quark-gluon interactions decreases as the energy scale of the interaction increases (equivalently, the length scale of the interaction decreases). This phenomenon is known as asymptotic freedom; essentially, quarks and gluons in close proximity behave as nearly free particles, while those far apart interact strongly.
%
%While there is no analytic proof of QCD, there is a large body of evidence supporting its predictions.
%
%\subsection{Feynman diagrams}
%Feynman diagrams are a powerful tool in calculating the likelihood of interactions between fundamental particles. Not only are they an intuitive diagrammatic representation of processes, but they can also be directly translated into an equation that can be integrated to give the transition amplitude between the initial and final state in a process.
%
%The rules that provide the convention for this translation are called Feynman rules. They are motivated by the quantum field theoretical formulation of the Standard Model, but what makes these diagrams so powerful is that once the rules are laid down, knowledge of QFT is not required. The derivation of the same equations from QFT can be very involved and messy, and Feynman diagrams are a clear and concise packaging of the same.
%\begin{figure}[H]
%\centering
%	\begin{subfigure}{0.4\textwidth}
%	\centering
%		\includegraphics[width=0.5\linewidth]{Bhabha_S_channel.png}
%	\end{subfigure}
%	\begin{subfigure}{0.4\textwidth}
%	\centering
%		\includegraphics[width=0.5\linewidth]{Bhabha_T_channel.png}
%	\end{subfigure}
%	\caption{Bhabha scattering showing electron-positron annihilation in s-channel (left) and scattering in t-channel (right). The interaction is mediated by the photon, the gauge boson that mediates electromagnetic interactions}.
%	\label{fig:bhabha}
%\end{figure}
%Figure \ref{fig:bhabha} shows Bhabha scattering, an electromagnetic process involving the interaction of an electron and a positron, mediated by a photon. The Feynman rules assign functionals to the propagators (the straight/wavy lines in the diagram) and the vertices, from which we can obtain the amplitudes for this process.

\chapter{Transfer factor R and the uncertainties associated to it}\label{ch:Results}

\section{MCFM}
Monte Carlo for FeMtobarn processes (MCFM) is a program that calculates cross sections for femtobarn-level processes at leading order(LO) or next to leading order (NLO) QCD. In this study, MCFM v8.0 \cite{MCFM1, MCFM2, MCFM3, MCFM} is used to generate cross sections of \ZZ and \Zg processes at NLO, with a selection of generator level cuts. The generation parameters in MCFM allow fine control over the sample, such as PDF sets, photon isolation, lepton and photon $p_T$ and $\eta$, renormalization and factorization scales, etc. The samples are generated with cuts on $E_T^{miss} = p_T(Z\to \nu\nu)$ for the $ZZ$ process and $p_T(\gamma)$ for the $Z+\gamma$ process. A ratio of these cross sections is taken to obtain the $R$ distribution as a function of $p_T$. The uncertainty on $R$ is calculated by varying several parameters at the generator level, such as the renormalization and factorization scales, the PDF sets used, photon fragmentation, etc. The contributions of the $q \bar{q}$ and $gg$ processes are estimated separately.

In MCFM generated events, leptonically decaying $Z$ boson are constrained to an electron-positron pair only, i.e. $Z\to ee$. As electrons and muons have similar properties with the exception of mass, simply the branching fraction of $Z\rightarrow ee$ must be accounted for to obtain the inclusive value of $R$.
\begin{equation}\label{eq:R_inc}
	R_{inc} = R * \frac{BR(Z\rightarrow ee)}{BR(Z \rightarrow ee)*BR(Z\rightarrow \nu\nu)*2}
\end{equation}

\renewcommand{\thefootnote}{\fnsymbol{footnote}} 
Table \ref{table:default} lists the generator level settings used for the $ZZ$ and $Z+\gamma$ processes. All lepton cuts are consistent with the ones used in the ATLAS Z+$E_T^{miss}$ analysis \cite{ZH_ATLAS}, as shown in Table \ref{table:event_selection}.
\begin{table}[H]
\begin{center}
	\begin{tabular}{|c|c|c|}
	\hline
	\textbf{Cuts} &$ZZ \rightarrow ee\nu\nu$ & $Z(\rightarrow ee)+\gamma$\\
	\hline
	Process ID & 87 & 300\\
	$M_{ee}$ & $76 < M_{ee} < 106$ GeV & $76 < M_{ee} < 106$ GeV\\
	$M_{\nu\nu}$ & - & -\\
	Order & NLO & NLO\\
	PDF set & CT14 & CT14\\
	$p_T^{\text{lead}}(e)$ & $> 30$ GeV & $> 30$ GeV\\
	$|\eta^{lead}(e)|$ & $< 2.47$ & $< 2.47$\\
	$p_T^{\text{sublead}}(e)$ & $> 20$ GeV & $> 20$ GeV\\
	$|\eta^{sublead}(e)|$ & $< 2.47$ & $< 2.47$\\
	$p_T(V)$\footnotemark & $> 90$ GeV & $> 90$ GeV\\
	\hline
	\end{tabular}
	\caption{Settings in input.DAT for MCFM}
	\label{table:default}
\end{center}
\end{table}

The constraint on $M_{ee}$ in the case of $Z+\gamma$ suppresses the FSR process by ensuring that the lepton pair are from a $Z$ decay only. In addition, the renormalization and factorization scales for both processes are set to be $H_T = \sum_i p_{T,i}$. Photon isolation is implemented using the Frixione \cite{frixione} method, with $R_0=0.4$, $\epsilon=0.075$ and $n=1$. These parameters are further explained in Section \ref{subsec:photon_fragmentation}.

\footnotetext{$V$ is a vector boson: $Z(\to\nu\nu)$ for the $ZZ$ process; $\gamma$ for the $Z\gamma$ process}
\renewcommand{\thefootnote}{\arabic{footnote}}

\section{Preliminary Results}
Using the settings listed in Table \ref{table:default}, the cross sections for $ZZ\to ee\nu\nu$ and $Z\gamma\to ee\gamma$ are generated, as shown in Figure \ref{xsecs}. Throughout this analysis, these samples are the reference.

\begin{figure}[H]
\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{ZZ_xsec.png}
		\caption{}
		\label{subfig:ZeeZvv}
	\end{subfigure}	
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{Zg_xsec.png}
		\caption{}
		\label{subfig:Zeeg}	
	\end{subfigure}
	\caption{NLO and LO cross sections of $ZZ\to ee\nu\nu$ (left) and $Z\gamma\to ee\gamma$ (right) processes with the cuts as in Table 1. The vertical axis is in $\log_{10}$ scale. The leptonically decaying $Z$ boson decays to an $e^+e^-$ pair. There is no flavor constraint on the neutrinos.}
	\label{xsecs}
\end{figure}

The ratio $R = \sigma(ZZ\rightarrow ee\nu\nu)/\sigma(Z\gamma\rightarrow ee\gamma)$ is shown in Figure \ref{fig:Rcurve}, taken as the ratio of the cross sections in Figures \ref{subfig:ZeeZvv} and \ref{subfig:Zeeg}. Additional events are generated with \met and $p_T(\gamma) > 400$ GeV for the two processes respectively to increase statistics. 
\begin{figure}[H]
	\centering
	\includegraphics[width= 0.6\textwidth]{R.png}
	\caption{The transfer factor $R$ as a function of $p_T$, taken as a ratio of  the $ZZ\to ee\nu\nu$ and $Z\gamma\to ee\gamma$ cross sections at both LO and NLO. The leptonically decaying $Z$ boson decays to an $e^+e^-$ pair.}
	\label{fig:Rcurve}
\end{figure}
The $R$ value is observed to increase from $\approx 0.39$ at 50 GeV to $\approx 0.52$ at high $p_T$, where it reaches a plateau. When the branching ratio of $Z$ boson decaying selectively to $e^+e^-$, or to $\nu\nu$, is accounted for as shown in Equation \ref{eq:R_inc}, the resulting ratio $R(p_T)$ is shown in Figure \ref{fig:RcurveBR}, which shows the ratio of $\sigma(ZZ)$ to $\sigma(Z\gamma)$, i.e. if the $Z$ bosons do not decay further. The value of $R$ is observed to increase from $\approx 0.98$ at 50 GeV to $\approx 1.3$ at high $p_T$, in reasonable agreement with the simple approximate calculation presented in Chapter \ref{ch:theory} of $R \approx 1.28$.
\begin{figure}[H]
	\centering
	\includegraphics[width = 0.6\textwidth]{R_BR.png}
	\caption{The transfer factor $R$ as a function of $p_T$ at both LO and NLO, adjusted for the $Z\rightarrow ee$ and $Z\rightarrow \nu\nu$ branching ratios. This shows the $R=\sigma(ZZ)/\sigma(Z\gamma)$, where the $Z$ bosons do not decay.}
	\label{fig:RcurveBR}
\end{figure}

Figure \ref{fig:yy} shows the normalized rapidity distributions for missing transverse momentum $(Z\to\nu\nu)$ and the photon respectively. The photon rapidity is restricted to $|\eta|<2.5$.
\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{yy.png}
	\caption{The normalized distributions showing the differential cross sections of \ZZ and \Zg processes as a function of the rapidity of the vector boson y(V) ($Z\to\nu]nu$ for \ZZ, or $\gamma$ for \Zg). The rapidity range for the photon is restricted to be $|\eta|<2.5$}
	\label{fig:yy}
\end{figure}
Figures \ref{fig:leppt} and \ref{fig:leptony} further illustrate the topology of the events by showing normalized distributions for the leading and subleading lepton $p_T$ and rapidity.
\begin{figure}[H]
\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{leadpt.png}
		\caption{}
		\label{fig:leadpt}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{subleadpt.png}
		\caption{}
		\label{fig:subleadpt}
	\end{subfigure}
	\caption{Normalized distributions showing the differential cross section as a function of the transverse momentum of the leading (left) and subleading (right) leptons for the two processes.}
	\label{fig:leppt}
\end{figure}
\begin{figure}[H]
\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{leady.png}
		\caption{}
		\label{fig:leady}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{subleady.png}
		\caption{}
		\label{fig:subleady}
	\end{subfigure}
	\caption{Normalized distributions showing the differential cross section as a function of the rapidity of the leading (left) and subleading (right) leptons for the two processes.}
	\label{fig:leptony}
\end{figure}

\begin{figure}[H]
\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{ZZ_subproc.png}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{Zg_subproc.png}
	\end{subfigure}	
\caption{The cross sections of $ZZ\to ee\nu\nu$ (left) and $Z\gamma\to ee\gamma$ (right) as a function of $p_T$, from the contributing $q\bar{q}$, $qg$ and $gg$ processes. The leptonically decaying $Z$ boson decays to an electron-positron pair}
\label{fig:xsec_gg_qq}
\end{figure}

Gluon-gluon processes contribute to 8.6\% of the total cross section for the $ZZ$ process and 2.5\% of the $Z+\gamma$ process. As shown in Figure \ref{fig:xsec_gg_qq}, the $qg+q\bar{q}$ and $gg$ contributions to the $ZZ$ and $Z\gamma$ cross section, it is seen that at low $p_T$, gluon-gluon processes contribute more than at high $p_T$.

The $R_{gg}$ distribution, shown in Figure \ref{fig:R_ggonly} is observed to approach an asymptotic value at a much higher $p_T = 1.5$ TeV.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{R_ggonly.png}
\caption{$R_{gg}(p_T)$, computed from the contributions of the $gg$ subprocess to the cross sections of $ZZ$ and $Z\gamma$. The curve reaches a plateau at a much higher $p_T$ than for contributions from the $q\bar{q}$ process only. The leptonic $Z$ bosons decay to an $ee$ pair.}
\label{fig:R_ggonly}
\end{figure}

\subsection{Uncertainty from Missing Higher Order Corrections}
\textbf{Note: I intend to add an appendix detailing the process of regularization and renormalization with examples. I will need to refresh my theory.}

In QCD calculations, higher order perturbative corrections may be added to the vertices or propagators in a Feynman diagram. An example illustrating the these 'loop' corrections is shown in Figure \ref{fig:loop_corr}. Physically, these corrections occur at very small time scales. These perturbative corrections lead to divergent integrals that are progressively more difficult to calculate at higher orders. A perfect calculation, carried out up to infinite orders, would give the exact cross section. However current technological capabilities limit the order to which calculations can be carried out.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{renormalize_diagram.png}
\caption{Loop corrections to the propagator and vertex illustrated using a Feynman diagram showing $\gamma\to e\nu$, for example. These loops represent interactions that happen at very small distance scales (and corresponding, very high energy scales), and are calculated perturbatively in QCD.}
\label{fig:loop_corr}
\end{figure}

While calculating loop corrections, two kinds of divergences are encountered: infrared divergences, and ultraviolet divergences. Infrared divergences occur when the integral diverges due to the contributions of particles with very low energies (or equivalently, interactions at large distances), and typically involve terms featuring $1/k$, thus diverging as $k\to 0$. Ultraviolet divergences are logarithmic divergences involving the term $\int d^4k\ 1/k^4$. Integrals of this form simplify as terms involving $\int ln(k) dk$ that diverge as the integration variable approaches $\infty$, occurring at very high energy scales, or equivalently, interactions at extremely short distances. They correspond to physics at long and short distances. Here, long distances are those where soft interactions take place, away from the hard parton-parton interaction. Short distances are those where the hard parton parton interactions occur.

Thus, it is necessary to regularize such integrals, i.e. render the divergences finite, or have them cancel out somehow. One method of addressing these divergences is to introduce a cutoff scale $\Lambda$ as the (upper or lower) limit in the momentum integrals, such as through the Pauli-Villars regularization. The divergences will then be proportional to log$\Lambda/\mu^2$, where $\mu^2$ is some arbitrary scale, an artifact of the regularization.

Dimensional regularization is another, more effective method of regularization, where the power of the momentum integration is shifted by an infinitesimally small amount $2\epsilon$, i.e. $\int d^4q/(2\pi)^4 q... \to \mu^{2\epsilon}\int d^{4-2\epsilon}q/(2\pi)^4 q...$ A prefactor $\mu^{2\epsilon}$ is introduced, where $\mu$ is an arbitrary scale, to ensure that all observables have the dimension of mass. Thus, regularization envelops the effect of these divergences into the arbitrary scale $\mu$. Upon renormalizing these regularized integrals, the $1/\epsilon$ divergent terms cancel out, leaving only the scale $\mu$ to be addressed. In QCD calculations, this scale appears as part of a scale dependent parameter, namely the running strong coupling constant ($\alpha_s(\mu)$).

The infrared divergences are addressed by the inclusion of the factorization scale $\mu_F$, while the ultraviolet divergences are addressed by the inclusion of the renormalization scale $\mu_R$. These parameters are arbitrary, and are set by hand. These are then varied between $\frac{1}{2}\mu < \mu < \ 2\mu$ to obtain an indication of the dependence of the matrix element on the scales, and thus, the uncertainty around the chosen scale. 

Perturbative QCD calculations get progressively more computationally expensive as the order of the perturbative theory increases. Thus, perturbative QCD calculations are only carried out up to a fixed order. There is a difference in the cross sections obtained from one order to the next, and thus, a contribution from the uncalculated higher perturbative orders is expected. To account for the missing higher order corrections, $K-$factors are introduced, defined in Equation \ref{eq:K_factor} as the ratio of the cross section at the highest available order to the leading order cross section.

To address uncertainties associated with the scale in this study, the prescription used in Ref \cite{precise_scale}, section 4 is followed. The central scale, $\mu_0$ is chosen to be $H_{T}/2$ for both \ZZ and \Zg samples (where $H_T$ is the scalar sum of the transverse momentum of all particles after collision, $\sum_{i} p_{T,i}$), and seven-point variations are applied, i.e.
\begin{equation}
\frac{\mu_i}{\mu_0} = (1,1),(1,2),(2,1),(2,2),(0.5,1),(1,0.5),(0.5,0.5)\\
\label{eq:scale}
\end{equation}
where $i=0,...,6$. The central cross section value is taken to be the mean of the maximum and minimum cross sections resulting from this variation, and the uncertainty to be the half the difference between the same.
\begin{align}
\sigma_{NLO}^{(V)} &= \frac{1}{2}\left[\sigma_{NLO}^{(V,max)} + \sigma_{NLO}^{(V,min)}\right]\label{eq:scale_central}\\
\delta\sigma_{NLO}^{(V)} &= \frac{1}{2}\left[\sigma_{NLO}^{(V,max)} - \sigma_{NLO}^{(V,min)}\right]
\label{eq:scale_central2}
\end{align}
where
\begin{align}
\sigma_{NLO}^{(V,max)} &= max\left\lbrace\sigma_{NLO}^{(V)}(p_{T}(V),\mu_i)|0\leq i \leq 6\right\rbrace\\
\sigma_{NLO}^{(V,min)} &= min\left\lbrace\sigma_{NLO}^{(V)}(p_{T}(V),\mu_i)|0\leq i \leq 6\right\rbrace
\end{align}
and $V = Z\to\nu\nu$ for \ZZ, or $V = \gamma$ for \Zg. This uncertainty is propagated to $R$.

The two processes are kinematically similar at high $p_T$. Thus, naively, a cancellation of the contribution due to missing higher order corrections would be expected between the two processes due to this correlation. To estimate the degree of correlation between the processes, the process dependent part of the cross sections may be used. Since the study is undertaken at NLO, the $K$-factor is defined as in Equation \ref{eq:K_factor}.
\begin{equation}
K_{NLO}^{(V)} = \sigma_{NLO}^{(V)}(p_T)/\sigma_{LO}^{(V)}(p_T)
\label{eq:K_factor}
\end{equation}

To estimate the unknown process dependent correlation effects, the difference between the $K$-factors of the \ZZ and \Zg processes is taken.
\begin{equation}
\delta^{(2)} \sigma_{NLO} = K_{NLO}^{(\gamma)}(p_T) - K_{NLO}^{(Z)}(p_T)
\label{eq:K_factor_unc}
\end{equation}

Applying the above prescription, the variation of scales for cross sections of $ZZ\to ee\nu\nu$ and $Z\gamma\to ee\gamma$ are shown in Figure \ref{fig:scale_xsec} below.
\begin{figure}[H]
\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{zz_scale.png}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{zg_scale.png}
	\end{subfigure}
	\caption{The scale variations around the cross sections of $ZZ\to ee\nu\nu$(left) and $Z\gamma\to ee\gamma$(right)}
	\label{fig:scale_xsec}
\end{figure}

At 100 GeV, the deviation from the central value is about 3\% for both processes and increases to ~10\% at high $p_T$. Here, the prescription in Equations \ref{eq:scale_central} and \ref{eq:scale_central2} is used to compute the central value and uncertainty.\\ Treating the scales as correlated between the processes, the scale variation for the transfer factor $R$ is shown in Figure \ref{fig:R_scale}. The central value of $R$ and the uncertainty band around it is taken according to Equations \ref{eq:scale_central} and \ref{eq:scale_central2} applied to $R$.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{R_scale.png}
\caption{The transfer factor $R = \sigma(ZZ\to ee\nu\nu)/\sigma(Z\gamma\to ee\gamma)$(top), with the scales varied in a correlated manner for both $ZZ$ and $Z\gamma$ processes. The bottom plot shows the relative ratio $R_i/R_0$ of the varied transfer factors to the central value.}
\label{fig:R_scale}
\end{figure}
The correlated scale uncertainty around $R$ is lower compared to that of the individual cross sections. At 100 GeV, $R \approx 0.4 \pm 0.037$, or an uncertainty of 1\%. At high $p_T$, $R\approx 0.55 \pm 0.01$, the uncertainty is 1.8\%.

To study the uncertainty due to unknown process dependent correlation effects, the $K$-factor study is undertaken, following the prescription in Equations \ref{eq:K_factor} and \ref{eq:K_factor_unc}. Figure \ref{fig:K_pt}
\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{K_pt.png}
	\caption{The $K$ factor to estimate the unknown process dependent correlations, defined as $\sigma_{NLO}(V)/\sigma_{LO}(V)$. The bottom plot shows the $K$-factor difference relative to $K(Z)$.}
	\label{fig:K_pt}
\end{figure}

\subsection{Uncertainty associated with Parton Distribution Functions}
A proton is a baryon, i.e. it is composed of quarks and several gluons. In a proton-proton collision, it is these quarks and gluons, called $partons$ that actually interact. This is illustrated by Figures \ref{fig:ZZ} and \ref{fig:Zg}, which show the Feynman diagrams for quark-quark and gluon-gluon interactions. Thus it is important to know the momentum of the interacting partons. It is not possible to deterministically know the momentum of the partons, as it is the momentum of the protons that is set during the experiment. However, the fraction of the proton momentum that is carried by the partons can be modelled as probability distributions.

Parton Distribution Functions (PDFs) characterize the fraction of proton momentum carried by partons as probability distributions. PDF sets are collections of PDFs that model the uncertainty associated with parton momenta. 

QCD predicts quantitatively the rate of change of parton distributions when the energy scale $Q^2$ varies, governed by the DGLAP equations \cite{DGLAP}, in the region where perturbative calculations can be applied. While the DGLAp differential equations give the energy scale $Q^2$ dependence, they cannot definitively predict the $x$ dependence of the parton distributions at a given $Q^2$, and must be extracted form data. Thus, PDFs sets are obtained by fitting on a large number of cross section data points, on a grid of $Q^2$ and $x$ values from several experiments. This work is carried out by groups such as  MSTW \cite{MSTW, MSTW2, MSTW3}, MMHT \cite{MMHT14}, NNPDF \cite{NNPDF}, etc.

\textbf{Note: I could discuss DGLAP equations here or in an appendix, and mention information regarding the data collections. I will also definitely add a PDF plot here.}

The PDF set used for reference is the \texttt{CT14}\cite{CT14} PDF set. The uncertainty on the PDFs is studied by using the 30 variations provided by the \texttt{PDF4LHC15} set\cite{PDF4}, constructed from the combination of \texttt{CT14,MMHT14} and \texttt{NNPDF3.0} PDF sets. These sets are provided by LHAPDF6\cite{LHAPDF}. \texttt{PDF4LHC15} provides a set of variations that include those determined by different groups (MSTW, CTEQ and NNPDF). The set used here is \texttt{PDF4LHC15\_nlo\_30}, consisting of 30 members.
\begin{figure}[H]
\centering
	\includegraphics[width = 0.7\textwidth]{R_pdf.png}
	\caption{The transfer factor $R = \sigma(ZZ)/\sigma(Z\gamma)$ (top), and the relative ratio $R_i/R_0$ of the transfer factor  calculated using PDF sets 1-30, with respect to set 0 which is taken as the central value. }
	\label{fig:PDF30var}
\end{figure}
\noindent Fig.\ref{fig:PDF30var} shows the comparison of the ratio $R(p_T)$ from the 30 member sets of \texttt{PDF4LHC15\_nlo\_30}. To measure the uncertainty due to these 30 sets, analogous to Equation 20 in Ref \cite{PDF4}, Equation \ref{eq:PDFerr} is used:
\begin{equation}\label{eq:PDFerr}
	\delta^{PDF}R = \sqrt{\sum^{N_{mem}}_{k=1} (R^{(k)} - R^{(0)})^2}
\end{equation}
where $N_{mem}$ is the number of member sets in the group, in this case, 30.

\noindent The combined uncertainty around $R \approx 0.40$ is $\pm 0.01$, or about 2.3\%, at 100 GeV. The uncertainty is about 2\% at high $p_T$ values, with $R \approx 0.51 \pm 0.01$.

\subsection{Photon Fragmentation and Isolation Uncertainty}\label{subsec:photon_fragmentation}
The \Zg process may contain photons that arise from the hadron showers. It is therefore important to isolate the prompt photon from hadronic activity. This reduces unwanted background from pion decays, or fragmentation processes.

Experimentally, photon isolation is implemented with the following selection:
\begin{equation}
\sum_{\in R_0} E_T(\text{had}) < \epsilon_h p_T^\gamma \text{\hspace{1cm} or \hspace{1cm}} \sum_{\in R_0} E_T(\text{had}) < E_T^{max}
\end{equation}
\label{eq:photon_isol}
limiting the transverse hadronic energy $E_T(had)$ in a cone of size $R_0 = \sqrt{\Delta\eta^2 + \Delta\phi^2}$ around the photon, to some fraction of the photon $p_T$, or some fixed small cut-off.

The smooth cone isolation method of Frixione \cite{frixione} is an alternative isolation procedure, which simplifies calculations by avoiding fragmentation contribuitions. The following isolation prescription is applied to the photon:
\begin{equation}
	\sum_{R_{j\gamma} \in R_0} E_T(\text{had}) < \epsilon_h p_T^\gamma \left(\frac{1-\cos R_{j\gamma}}{1-\cos R_0}\right)^n.
\end{equation}
\label{eq:frix_isol}
where $R_{j\gamma}$ is the separation of the photon and the $j^{th}$ hadron. This requirement constrains the sum of hadronic energy inside a cone of radius $R_{j\gamma}$, for all separations $R_{j\gamma}$ less than a chosen cone size $R_0$. This prescription allows soft radiation inside the photon cone, but collinear singularities are removed. The smooth cone isolation is infrared finite, thus fragmentation contributions do not need to be included. 

The two prescriptions are significantly different. The Frixione method has its advantages, namely that it is infrared finite, removes collinear singularies and avoids fragmentation effects. However, Frixione isolation is difficult to implement experimentally, while the relative isolation, given by Equation \ref{eq:photon_isol} is readily used in experimental analyses. For the purpose of this analysis, the Frixione method is used, and the parameters $\epsilon$ and $n$ are varied to get a handle on the uncertainty associated with the Frixione isolation method. In addition, the difference from the experimental isolation method is accounted for as part of the uncertainty.

In this analysis, $R_0$ is chosen to be 0.4 to agree with the experimental definition. The central value is chosen to be from the sample using smooth cone isolation (Frixione) with $\epsilon_h = 0.075$ and $n=1$. These parameters are varied within a reasonable range to assess the uncertainty as shown in Figure \ref{fig:photon_frag}.

\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{frag.png}
	\caption{$R$ distribution as a function of $p_T$, showing the uncertainty due to variation of photon isolation parameters $\epsilon_h$ and $n$ in the smooth cone isolation procedure (Frixione), and $\epsilon_h$ in the photon isolation procedure. The lower panel shows the relative deviation of the varied sets from the central value, as well as the uncertainty band.}
	\label{fig:photon_frag}
\end{figure}

The uncertainty is calculated from the four sets listed in Figure \ref{fig:photon_frag}:
\begin{equation}
\begin{split}
\delta R_i &= |R_i - R_{ref}| \hspace{2cm}  i \in (1,2,3,4)\\
\delta R &= \sqrt{\max_{i=1,2,3}(\delta R_i)^2 + (\delta R_4)^2}
\end{split}
\end{equation}
as the effects assessed by changing the isolation definition in set 4, and varying the parameters in sets 1-3 are different.\\
The uncertainty is $< 2\%$ over the whole $p_T$ range.

\chapter{Additional Figures}
\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{K_y.png}
	\caption{K factor as a function of rapidity}
	\label{fig:K_y}
\end{figure}
\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{dphi.png}
	\caption{dphi(Z,V)}
	\label{fig:dphi}
\end{figure}
\begin{figure}[H]
\centering
	\includegraphics[width=0.7\textwidth]{dy.png}
	\caption{dy(Z,V)}Matter and Antimatter in the Universe
\end{figure}


%Bibliography
\begin{thebibliography}{9}
%1
\bibitem{griff}
	\textbf{D. J. Griffiths}, Introduction to Elementary Particles 2nd Edition, 2004 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim

\bibitem{SM}
	PBS NOVA, Fermilab, Office of Science, United States Department of Energy, Particle Data Group.
	
\bibitem{QED}
	\textbf{Richard Feynman}, QED: The Strange Theory of Light and Matter. Princeton University Press, 1986.
	
\bibitem{confinement}
\textbf{J. Greensite (2011)}. An introduction to the confinement problem. Springer. ISBN 978-3-642-14381-6.
	
\bibitem{nu1}
	\textbf{The Super-Kamiokande Collaboration}, Evidence for oscillations of atmospheric neutrinos, Phys.Rev.Lett.81:1562-1567, 1998, \href{https://arxiv.org/abs/hep-ex/9807003}{\texttt{arXiv:hep-ex/9807003}}
	
\bibitem{nu2}
	\textbf{The SNO Collaboration}, Measurement of the rate of $\nu_e + d \to p + p + e^-$ interactions produced by ${}^8$B solar neutrinos at the Sudbury Neutrino Observatory, Phys.Rev.Lett.87:071301,2001, \href{https://arxiv.org/abs/nucl-ex/0106015}{\texttt{arXiv:nucl-ex/0106015}}
	
\bibitem{nu3}
	\textbf{The SNO Collaboration}, Direct Evidence for Neutrino Flavor Transformation from Neutral-Current Interactions in the Sudbury Neutrino Observatory, Phys.Rev.Lett.89:011301,2002, \href{https://arxiv.org/abs/nucl-ex/0204008}{\texttt{arXiv:nucl-ex/0204008}}
	
\bibitem{quarks_and_leptons}
\textbf{F. Halzen, A. Martin}, Quarks and Leptons: An introductory course in model particle physics, John Wiley and Sons, 1984.

\bibitem{collider_physics}
\textbf{V. Barger, R. Phillips}, Collider Physics (Frontiers in Physics), Avalon Publishing, 1997.
%2	

\bibitem{cronin_fitch}
\textbf{J. H. Christenson, J. W. Cronin, V. L. Fitch, and R. Turlay}, Evidence for the 2$\pi$ Decay of the $K_2^0$ Meson, Phys. Rev. Lett. 13, 138 (1964), \url{https://doi.org/10.1103/PhysRevLett.13.138}

\bibitem{CKM}
\textbf{M. Kobayashi T. Maskawa}, $CP$-Violation in the Renormalizable Theory of Weak Interaction, Progress of Theoretical Physics, Volume 49, Issue 2, 1 February 1973, 652657, \url{https://doi.org/10.1143/PTP.49.652}

\bibitem{CP1}
\textbf{KTEV Collaboration}, Observation of Direct $CP$ Violation in $K_{S,L}\to \pi\pi$ Decays, Phys.Rev.Lett.83:22-27,1999, \href{https://arxiv.org/abs/hep-ex/9905060}{\texttt{arXiv:hep-ex/9905060}}

\bibitem{CP2}
\textbf{NA48 Collaboration}, A new measurement of direct $CP$ violation in two pion decays of the neutral kaon,  	Phys.Lett.B465:335-348,1999, \href{https://arxiv.org/abs/hep-ex/9909022}{\texttt{arXiv:hep-ex/9909022}}

\bibitem{CP3}
\textbf{BaBar collaboration}, Measurement of $CP$-violating asymmetries in $B^0$ decays to $CP$ eigenstates, Phys.Rev.Lett.86:2515-2522,2001, \href{https://arxiv.org/abs/hep-ex/0102030}{\texttt{arXiv:hep-ex/0102030}}

\bibitem{CP4}
\textbf{Belle Collaboration}, Observation of Large $CP$ Violation in the Neutral $B$ Meson System, Phys.Rev.Lett.87:091802,2001, \href{https://arxiv.org/abs/hep-ex/0107061}{\texttt{arXiv:hep-ex/0107061}}

\bibitem{CP5}
\textbf{LHCb Collaboration}, Measurement of $CP$ asymmetry in $D^0 \to K^+ K^-$ and $D^0 \to \pi^+ \pi^-$ decays, JHEP 07 (2014) 041, \href{https://arxiv.org/abs/1405.2797}{\texttt{arXiv:1405.2797 [hep-ex]}}

\bibitem{CP6}
\textbf{LHCb Collaboration}, First observation of $CP$ violation in the decays of $B^0_s$ mesons, \href{https://arxiv.org/abs/1304.6173}{\texttt{arXiv:1304.6173 [hep-ex]}}
%3
\bibitem{Higgs}
	\textbf{ATLAS Collaboration}, Observation of a New Particle in the Search for the Standard Model Higgs boson with the ATLAS detector at the LHC, Phys.Lett. B716 (2012) 1-29, \href{https://arxiv.org/abs/1207.7214}{\texttt{arXiv:1207.7214 [hep-ex]}}
	
\bibitem{grav_inc}
	\textbf{A. O. Sushkov, W. J. Kim, D. A. R. Dalvit, S. K. Lamoreaux}, New experimental limits on non-Newtonian forces in the micrometer-range, Phys. Rev. Lett. 107, 171101 (2011), \href{https://arxiv.org/abs/1108.2547}{\texttt{arXiv:1108.2547 [quant-ph]}}
	
\bibitem{DM_inc}
	\textbf{Jaco de Swart, Gianfranco Bertone, Jeroen van Dongen}, How Dark Matter came to matter, Nature Astronomy 1, 0059 (2017), \href{https://arxiv.org/abs/1703.00013}{\texttt{arXiv:1703.00013 [astro-ph.CO]}}
	
\bibitem{DE}
	\textbf{P. J. E. Peebles, Bharat Ratra},The Cosmological Constant and Dark Energy (2002), \href{https://arxiv.org/abs/astro-ph/0207347}{\texttt{arXiv:astro-ph/0207347}}

\bibitem{Planck}
	\textbf{Planck Collaboration}, Planck 2015 results. XIII. Cosmological parameters (2016), \href{https://arxiv.org/abs/1502.01589}{\texttt{arXiv:1502.01589 [astro-ph.CO]}}

\bibitem{DM_comp}
\textbf{N. Jarosik et al.}, Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Sky Maps, Systematic Errors and Basic Results, Astrophys. J. Suppl. 192 14 (2011) [1001.4744], \href{https://arxiv.org/abs/1001.4744}{\texttt{arXiv:1001.4744 [astro-ph.CO]}}

\bibitem{neutrino2}
\textbf{M.C.Gonzalez-Garcia, Michele Maltoni}, Phenomenology with Massive Neutrinos, Phys.Rept.460:1-129,2008, \href{https://arxiv.org/abs/0704.1800}{\texttt{arXiv:0704.1800 [hep-ph]}}

\bibitem{neutrino_mass}
\textbf{Vernon Barger, Danny Marfatia, Kerry Lewis Whisnant}, The Physics of Neutrinos (2012), Princeton University Press, ISBN 0-691-12853-7

\bibitem{Baryon_Asymmetry}
\textbf{Laurent Canetti, Marco Drewes, Mikhail Shaposhnikov}, Matter and Antimatter in the Universe, New J. Phys. 14 (2012) 095012, \href{https://arxiv.org/abs/1204.4186}{\texttt{arXiv:1204.4186 [hep-ph]}} 

\bibitem{hierarchy1}
\textbf{S. Weinberg}, Implications of Dynamical Symmetry Breaking, Phys. Rev. D13 (1976) 974996, \url{https://doi.org/10.1103/PhysRevD.13.974}

\bibitem{hierarchy2}
\textbf{S. Weinberg}, Implications of Dynamical Symmetry Breaking:  An Addendum, Phys. Rev. D19 (1979) 12771280, \url{https://doi.org/10.1103/PhysRevD.19.1277}

\bibitem{hierarchy3}
\textbf{L. Susskind}, Dynamics of spontaneous symmetry breaking in the Weinberg-Salam theory, Phys. Rev. D20 (1979) 26192625, \url{https://doi.org/10.1103/PhysRevD.20.2619}

\bibitem{hierarchy4}
\textbf{E. Gildener}, Gauge Symmetry Hierarchies, Phys. Rev. D14(1976) 1667, \url{https://doi.org/10.1103/PhysRevD.14.1667}

%4
\bibitem{galaxy}
	\textbf{Begeman, K. G., Broeils, A. H., Sanders, R. H.}, Extended rotation curves of spiral galaxies - Dark haloes and modified dynamics, Monthly Notices of the Royal Astronomical Society (ISSN 0035-8711), vol. 249, April 1, 1991, p. 523-537.
	
%5
\bibitem{DM_searches}
\textbf{Felix Kalhoefer}, Review of LHC Dark Matter searches, Int.J.Mod.Phys. A32 (2017) 1730006, \href{https://arxiv.org/abs/1702.02430}{\texttt{arXiv:1702.0243 [hep-ph]}}

\bibitem{mono_j}
\textbf{Philip Harris, Valentin V. Khoze, Michael Spannowsky, Ciaran Williams}, Closing up on Dark Sectors at Colliders: from 14 to 100 TeV, Phys. Rev. D 93, 054030 (2016), \href{https://arxiv.org/abs/1509.02904}{\texttt{arXiv:1509.02904 [hep-ph]}}

\bibitem{mono_V}
\textbf{Jing-Yuan, Edward W. Kolb, Lian-Tao Wang}, Dark matter coupling to electroweak gauge and Higgs bosons: an effective field theory approach, Phys.Dark Univ. 2 (2013) 200-218, \href{https://arxiv.org/abs/1305.0021}{\texttt{arXiv:1305.0021 [hep-ph]}}

\bibitem{mono_h}
\textbf{ATLAS Collaboration}, Search for dark matter produced in association with a Higgs boson decaying to two bottom quarks in pp collisions at $\sqrt{s} = 8$ TeV with the ATLAS detector, Phys. Rev. D 93, 072007 (2016), \href{https://arxiv.org/abs/1510.06218}{\texttt{arXiv:1510.06218 [hep-ex]}}

\bibitem{ZH_ATLAS}
	\textbf{ATLAS Collaboration}, Search for an invisibly decaying Higgs boson or dark matter candidates produced in association with a Z boson in pp collisions at $\sqrt{s}$ = 13 TeV with the ATLAS detector, PLB 776 (2017), 318, \href{https://arxiv.org/abs/1708.09624}{\texttt{arXiv:1708.09624 [hep-ex]}}
	
\bibitem{antikt}
	\textbf{M. Cacciari, G.P. Salam and G. Soyez}, The anti-$k_t$ jet clustering algorithm, JHEP 04 ()2008 063, \href{https://arxiv.org/abs/0802.1189}{\texttt{arXiv:0802.1189 [hep-ph]}}
	
\bibitem{cell_cluster}
	\textbf{ATLAS collaboration}, Topological cell clustering in the ATLAS calorimeters and its performance in LHC Run 1, Eur. Phys, J. C 77 (2017) 490, \href{https://arxiv.org/abs/1603.02934}{\texttt{arXiv:1603.02934 [hep-ex]}}
	
\bibitem{jet_calib}
	\textbf{ATLAS collaboration}, Jet Calibration and Systematic Uncertainties for Jets Reconstructed in the ATLAS Detector at $\sqrt(s)=13$ TeV, ATL-PHYS-PUB-2015-015 (2015) , \url{https://cdsweb.cern.ch/record/2028594}
	
\bibitem{fast_jet}
	\textbf{M. Cacciari, G.P. Salam and G. Soyez}, FastJet User Manual, Eur. Phys. J. C 72 (2012) 1896, \href{https://arxiv.org/abs/1111.6097}{\texttt{arXiv:1111.6097 [hep-ph]}}
	
\bibitem{parton_model}
	\textbf{Tung-Mow Yan, Sidney D. Drell}, The Parton Model and its Applications, Int. J. Mod. Phys. A 29, 1430071 (2014),  \href{https://arxiv.org/abs/1409.0051}{arXiv:1409.0051 [hep-ph]}
	
\bibitem{gamma_jet}
	\textit{Using $\gamma +$ jets to calibrate the Standard Model $Z(\rightarrow \nu\nu)+$ jets background to new processes at the LHC}\\
	\textbf{S. Ask, M. A. Parker, T. Sandoval, M. E. Shea, W. J. Stirling}\\
Cavendish Laboratory, University of Cambridge, CB3 0HE, UK; 2011\\
	\texttt{[arXiv:1107.2803]}

\bibitem{Z_coupling}
	\textit{2017 Review of Particle Physics - Particle Listings}\\
	\textbf{C. Patrignani \textit{et al}. (Particle Data Group)}\\
	Chin. Phys. C, 40, 100001 (2016)

\bibitem{MCFM1}
\textbf{J. Campbell, K. Ellis},	An update on vector boson pair production at hadron colliders, Phys. Rev. D
60
, 113006 (1999), \href{https://arxiv.org/abs/hep-ph/9905386}{arXiv:hep-ph/9905386}

\bibitem{MCFM2}
\textbf{J. M. Campbell, R. K. Ellis and C. Williams}, Vector boson pair production at the LHC, JHEP 1107, 018 (2011), \href{https://arxiv.org/abs/1105.0020}{arXiv:1105.0020 [hep-ph]}

\bibitem{MCFM3}
\textbf{J. M. Campbell, R. K. Ellis and W. Giele}, A Multi-threaded Version of MCFM, EPJ C75, 246 (2015), \href{https://arxiv.org/abs/1503.06182}{arXiv:1503.06182 [physics.comp-ph]}

\bibitem{MCFM}
\textbf{John Campbell, Keith Ellis, Walter Giele, Ciaran Williams},	Monte Carlo for FeMtobarn processes (MCFM) v8.0 User Manual, \url{https://mcfm.fnal.gov/}

\bibitem{DGLAP}
	\textbf{R. K. Ellis, W. J. Stirling, and B. R. Webber}, QCD and Collider Physics, Cambridge Monographs, 2003

\bibitem{precise_scale}
	\textbf{J.M. Lindert, S. Pozzorini, et al.}, Precise predictions for $V$+jets dark matter backgrounds, Eur. Phys. J. C (2017) 77: 829, \href{https://arxiv.org/abs/1705.04664}{\texttt{arXiv:1705.04664 [hep-ph]}}
	
\bibitem{CT14}
	\textbf{Sayipjamal Dulat, Tie Jiun Hou, Jun Gao, Marco Guzzi, Joey Huston, P. Nadolsky, Jon Pumplin, Carl Schmidt, Daniel Stump, C. P. Yuan}, New parton distribution functions from a global analysis of quantum chromodynamics, Phys. Rev. D 93, 033006 (2016), \href{https://arxiv.org/abs/1506.07443}{\texttt{arXiv:1506.07443 [hep-ph]}}

\bibitem{PDF4}
	\textbf{Jon Butterworth, Stefano Carrazza, et al}, PDF4LHC recommendations for LHC Run II, J. Phys. G: Nucl. Part. Phys. 43 023001 (2016),\href{https://arxiv.org/abs/1510.03865}{\texttt{arXiv:1510.03865 [hep-ph]}}

\bibitem{MSTW}
	\textbf{A.D. Martin, W.J. Stirling, R.S. Thorne, G. Watt}, Parton distributions for the LHC, Eur.Phys.J.C63:189-285,2009, \href{https://arxiv.org/abs/0901.0002}{\texttt{arXiv:0901.0002 [hep-ph]}}
	
\bibitem{MSTW2}
	\textbf{A.D. Martin, W.J. Stirling, R.S. Thorne, G. Watt}, Uncertainties on $\alpha_s$ in global PDF analyses and implications for predicted hadronic cross sections, Eur.Phys.J.C64:653-680,2009, \href{https://arxiv.org/abs/0905.3531}{\texttt{arXiv:0905.3531 [hep-ph]}}
	
\bibitem{MSTW3}
	\textbf{A.D. Martin, W.J. Stirling, R.S. Thorne, G. Watt}, Heavy-quark mass dependence in global PDF analyses and 3- and 4-flavor parton distributions, Eur.Phys.J.C70:51-72,2010, \href{https://arxiv.org/abs/1007.2624}{\texttt{arXiv:1007.2624 [hep-ph]}}
	
\bibitem{MMHT14}
	\textbf{L. A. Harland-Lang, A. D. Martin, P. Motylinski, R. S. Thorne}, Parton distributions in the LHC era: MMHT 2014 PDFs, Eur. Phys. J. C (2015) 75: 204, \href{https://arxiv.org/abs/1412.3989}{\texttt{arXiv:1412.3989 [hep-ph]}}
	
\bibitem{NNPDF}
	\textbf{The NNPDF collaboration, Ball, R.D., Bertone, V. et al.}, Parton distributions for the LHC Run II, J. High Energ. Phys. (2015) 2015: 40, \href{https://arxiv.org/abs/1410.8849}{\texttt{arXiv:1410.8849 [hep-ph]}}
	
\bibitem{LHAPDF}
	\textit{LHAPDF6: parton density access in the LHC precision era}\\
	\textbf{Andy Buckley, James Ferrando, Stephen Lloyd, Karl Nordstrom, Ben Page, Martin Ruefenacht, Marek Schoenherr, Graeme Watt}\\
	\texttt{arXiv:1412.7420}

\bibitem{frixione}
	\textit{Isolated photons in perturbative QCD}\\	
	\textbf{S. Frixione}\\
	Phys. Lett.B429(1998)369374, hep-ph/9801442
%	
%\bibitem{powheg}
%	POWHEG BOX - ZZ,WZ and WW production
%	\begin{itemize}
%	\item \textbf{P. Nason}\\
%	JHEP 0411 (2004) 040, hep-ph/0409146
%	\item \textbf{S. Frixione, P. Nason and C. Oleari}\\
%	JHEP 0711 (2007) 070, \texttt{arXiv:0709.2092}
%	\item \textbf{S. Alioli, P. Nason, C. Oleari and E. Re}\\
%	JHEP 1006 (2010) 043, \texttt{arXiv:1002.2581}
%	\item \textit{ZZ, WZ and W+W- production, including Gamma/Z interference, singly resonant contributions and interference for identical leptons}\\
%	\textbf{T. Melia, P. Nason, R. Rontsch, G. Zanderighi}\\
%	JHEP 1111 (2011) 078, \texttt{arXiv:1107.5051}
%	\item \textit{W+W-, WZ and ZZ production in the POWHEG-BOX-V2}\\
%	\textbf{P. Nason and G. Zanderighi}\\
%	Eur.Phys.J. C74 (2014) 2702, \texttt{arXiv:1311.1365}
%	\end{itemize}
%	
%\bibitem{pythia}
%	\textit{PYTHIA 8.1}\\
%	\textbf{T. Sjstrand, S. Mrenna and P. Skands}\\
%	JHEP05 (2006) 026, Comput. Phys. Comm. 178 (2008) 852. 
%	
%\bibitem{CT10}
%	\textit{New parton distributions for collider physics}
%	\textbf{Hung-Liang Lai, Marco Guzzi, Joey Huston, Zhao Li, Pavel M. Nadolsky, Jon Pumplin, C.-P. Yuan}
%	\texttt{arXiv:1007.2241}
%	
%\bibitem{MSTW2008}
%	\textit{Parton distributions for the LHC}\\
%	\textbf{A.D. Martin, W.J. Stirling, R.S. Thorne, G. Watt}
%	\texttt{arXiv:0901.0002}
	
\end{thebibliography}
\end{document}

%\subsection{Effect of Lepton Cuts}
%To check the effects of lepton cuts on the ratio, samples with the same parameters as those in Table \ref{table:default} are generated. However, we relax the cuts on leptons. Both the leading and subleading lepton should have $p_T > 5$ GeV, and $\eta <$ 10. In the lower $p_T$ regions, the cross section falls by nearly half in both processes. The ratio is affected by up to 15\% as seen in Figure \ref{fig:lepcut}, and therefore for all following studies the lepton cuts are applied as they emulate the experimental cuts needed in the analysis.
%\begin{figure}[H]
%\centering
%	\includegraphics[width = 0.8\linewidth]{lep_cuts.png}
%	\caption{Comparison of reference the $R$ distribution to the $R$ distribution without lepton cuts}
%	\label{fig:lepcut}
%\end{figure}